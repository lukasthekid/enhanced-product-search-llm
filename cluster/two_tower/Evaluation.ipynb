{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70d02c33-a86c-496c-828f-10f310660be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPUs found. Using CPU.\n",
      "TensorFlow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pyarrow.parquet as pq\n",
    "from typing import Tuple, Generator, Dict, Text\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 11925939\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Configure TensorFlow for optimal GPU usage\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"  # If using PyTorch elsewhere\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"{len(gpus)} GPU(s) Available: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPUs found. Using CPU.\")\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "PCOLLECTION_FILE_PATH = '../p_collection.pkl'\n",
    "SYNGET_U = 'models/model-u/weights'\n",
    "SYNGET_06 = 'models/model-0.6/weights'\n",
    "SYNGET_07 = 'models/model-0.7/weights'\n",
    "SYNGET_08 = 'models/model-0.8v2/weights'\n",
    "SYNGET_08_AC = 'models/model-0.8v2_all_candidates/weights'\n",
    "\n",
    "QUERY_TO_QUERY = '../qid2query.tsv'\n",
    "QREL_TEST = '../QREL/2023test.qrel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e3abe8-dba6-4f57-b47f-cee386e97df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QueryModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding user queries.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "        self.dense_layers.add(tf.keras.layers.Dense(128, activation='elu'))\n",
    "        self.dense_layers.add(tf.keras.layers.Dense(128))\n",
    "        self.dense_layers.add(tf.keras.layers.Lambda(lambda x: tf.keras.backend.l2_normalize(x, axis=-1)))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense_layers(inputs)\n",
    "\n",
    "\n",
    "class ProductModel(tf.keras.Model):\n",
    "    \"\"\"Model for encoding products.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Then construct the layers.\n",
    "        self.dense_layers = tf.keras.Sequential()\n",
    "        self.dense_layers.add(tf.keras.layers.Dense(128, activation='elu'))\n",
    "        self.dense_layers.add(tf.keras.layers.Dense(128))\n",
    "        self.dense_layers.add(tf.keras.layers.Lambda(lambda x: tf.keras.backend.l2_normalize(x, axis=-1)))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense_layers(inputs)\n",
    "\n",
    "\n",
    "class TwoTowerModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, candidates):\n",
    "        super().__init__()\n",
    "        self.query_model = QueryModel()\n",
    "        self.product_model = ProductModel()\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=candidates.batch(128).map(self.product_model)\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        query_embeddings = self.query_model(features[\"query_embedding\"])\n",
    "        product_embeddings = self.product_model(features[\"product_embedding\"])\n",
    "\n",
    "        return (\n",
    "            query_embeddings,\n",
    "            product_embeddings\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False):\n",
    "        query_embeddings = self.query_model(features[\"query_embedding\"])\n",
    "        product_embeddings = self.product_model(features[\"product_embedding\"])\n",
    "\n",
    "        return self.task(\n",
    "            query_embeddings, product_embeddings, compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b6c919-11cb-4265-8f9b-56a3b945afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_ground_truth(qid: int, qrel: pd.DataFrame, collection: pd.DataFrame) -> [int]:\n",
    "    df = qrel[(qrel['qid'] == qid) & (qrel['docid'].isin(collection['id'].values))]\n",
    "    df = df.sort_values(by='relevance_score', ascending=False)\n",
    "    return df.set_index('docid')['relevance_score'].to_dict()\n",
    "\n",
    "def produce_y_pred(topk: pd.DataFrame, y_true) -> dict:\n",
    "    # Create a result dictionary or DataFrame if needed\n",
    "    matched_scores = [y_true[_id] for _id in topk['id'].values]\n",
    "    result = {'docid': topk['id'].values, 'relevance_score': matched_scores}\n",
    "    return pd.DataFrame(result).set_index('docid')['relevance_score'].to_dict()\n",
    "        \n",
    "def normalized_discounted_cumulative_gain(temp_set, p=10):\n",
    "    dc_gain = 0\n",
    "    idc_gain = 0\n",
    "    for idx, value in enumerate(temp_set.values()):\n",
    "        pos = idx + 1\n",
    "        dc_gain += value / math.log2(pos + 1)\n",
    "        if pos == p:\n",
    "            break\n",
    "    for idx, value in enumerate(sorted(temp_set.values(), reverse=True)):\n",
    "        pos = idx + 1\n",
    "        idc_gain += value / math.log2(pos + 1)\n",
    "        if pos == p:\n",
    "            break\n",
    "    return round(dc_gain / idc_gain, 5)\n",
    "\n",
    "def precision_at_k(predicted_dict, ideal_dict, k):\n",
    "    # Get the top K docids from the predicted results\n",
    "    top_k_pred = list(predicted_dict.keys())[:k]\n",
    "    # Count the number of relevant documents in the top K predicted results\n",
    "    relevant_in_pred = sum([1 for docid in top_k_pred if ideal_dict.get(docid, 0) > 0])\n",
    "    # Precision is the number of relevant documents divided by K\n",
    "    return relevant_in_pred / k\n",
    "\n",
    "\n",
    "def recall_at_k(predicted_dict, ideal_dict, k):\n",
    "    # Get the top K docids from the predicted results\n",
    "    top_k_pred = list(predicted_dict.keys())[:k]\n",
    "    # Count the total number of relevant documents in the ideal results\n",
    "    total_relevant = sum([1 for score in ideal_dict.values() if score > 0])\n",
    "    # Count the number of relevant documents in the top K predicted results\n",
    "    relevant_in_pred = sum([1 for docid in top_k_pred if ideal_dict.get(docid, 0) > 0])\n",
    "    # Recall is the number of relevant documents in top K divided by the total number of relevant documents\n",
    "    return relevant_in_pred / total_relevant if total_relevant > 0 else 0\n",
    "\n",
    "def evaluate_two_tower(query_df: pd.DataFrame, qrel_df: pd.DataFrame, model,\n",
    "                       collection: pd.DataFrame, sentence_transformer: SentenceTransformer, k=10 ) -> (\n",
    "        float, float, float):\n",
    "    ndcg = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for _, row in query_df.iterrows():\n",
    "        if row.text is np.nan:\n",
    "            continue\n",
    "        #optimal ranking\n",
    "        y_true = produce_ground_truth(int(row.qid), qrel_df, collection)\n",
    "        # get the candidates\n",
    "        df_candidates = collection[collection['id'].isin(y_true.keys())].copy()\n",
    "        candidates = tf.data.Dataset.from_tensor_slices(np.stack(df_candidates['product_embedding'].values))\n",
    "        # build index\n",
    "        brute_force = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\n",
    "        brute_force.index_from_dataset(candidates.batch(128).map(model.product_model))\n",
    "        # predict top k\n",
    "        scores, indices = brute_force(np.array(sentence_transformer.encode([str(row.text)])), k=df_candidates.shape[0])\n",
    "        indices = indices.numpy().flatten()\n",
    "        scores = scores.numpy().flatten()\n",
    "        topk_df = df_candidates.iloc[indices].copy()\n",
    "        topk_df['score'] = scores\n",
    "        topk_df = topk_df.sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "        y_pred = produce_y_pred(topk_df, y_true)\n",
    "        ndcg.append(normalized_discounted_cumulative_gain(y_pred))\n",
    "        precision.append(precision_at_k(y_pred, y_true, k))\n",
    "        recall.append(recall_at_k(y_pred, y_true, k))\n",
    "\n",
    "    return np.mean(ndcg), np.mean(precision), np.mean(recall)\n",
    "\n",
    "\n",
    "def evaluate_gte(query_df: pd.DataFrame, qrel_df: pd.DataFrame,\n",
    "                       collection: pd.DataFrame, sentence_transformer: SentenceTransformer, k=10) -> (\n",
    "        float, float, float):\n",
    "    ndcg = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for _, row in query_df.iterrows():\n",
    "        if row.text is np.nan:\n",
    "            continue\n",
    "        #optimal ranking\n",
    "        y_true = produce_ground_truth(int(row.qid), qrel_df, collection)\n",
    "        # get the candidates\n",
    "        df_candidates = collection[collection['id'].isin(y_true.keys())].copy()\n",
    "        product_embeddings = np.stack(df_candidates['product_embedding'].values)\n",
    "        query_embedding = np.array(sentence_transformer.encode([str(row.text)]))\n",
    "        df_candidates['score'] = cosine_similarity(query_embedding, product_embeddings).flatten()\n",
    "        topk_df = df_candidates.sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "        y_pred = produce_y_pred(topk_df, y_true)\n",
    "        ndcg.append(normalized_discounted_cumulative_gain(y_pred))\n",
    "        precision.append(precision_at_k(y_pred, y_true, k))\n",
    "        recall.append(recall_at_k(y_pred, y_true, k))\n",
    "\n",
    "    return np.mean(ndcg), np.mean(precision), np.mean(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f28a28e-0424-467a-b0cc-f3e2c8d42d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model with (186, 2) queries on (115490, 4) pairs\n"
     ]
    }
   ],
   "source": [
    "collection = pd.read_pickle(PCOLLECTION_FILE_PATH)\n",
    "candidates = tf.data.Dataset.from_tensor_slices(np.stack(collection['product_embedding'].values))\n",
    "qid2query_df = pd.read_csv(QUERY_TO_QUERY, sep='\\t', names=['qid', 'text'], header=None)\n",
    "qrel_df = pd.read_csv(QREL_TEST, sep='\\t', names=['qid', '0', 'docid', 'relevance_score'], header=None)\n",
    "common_qids = set(qrel_df['qid']).intersection(set(qid2query_df['qid']))\n",
    "qrel_df = qrel_df[qrel_df['qid'].isin(common_qids)]\n",
    "qid2query_df = qid2query_df[qid2query_df['qid'].isin(common_qids)]\n",
    "sentence_transformer = SentenceTransformer('Alibaba-NLP/gte-large-en-v1.5', trust_remote_code=True)\n",
    "print(f'Testing the model with {qid2query_df.shape} queries on {qrel_df.shape} pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1211b7-b8c3-4987-8cbc-57156cfa573c",
   "metadata": {},
   "source": [
    "## Evaluate the pretrained GTE model embeddings\n",
    "As a second baseline we evaluate the retrieval performance of the [GTE_large](https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5) model on our specific dataset. This model ranks 32 on the overal [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard), rank 21 on retrieval tasks and rank 51 on reranking tasks (12.05.2024). As reference BM25s ranks at 182 and [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) ranks at 139."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27535fe2-f05c-4fe1-bce7-ac94342e7f88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10: 0.6173832795698925\n",
      "Precision@5: 0.6795698924731183\n",
      "Recall@5: 0.1788642520648675\n",
      "\n",
      "\n",
      "NDCG@10: 0.6173832795698925\n",
      "Precision@10: 0.5973118279569892\n",
      "Recall@10: 0.2615271195428554\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "score = evaluate_gte(qid2query_df, qrel_df, collection, sentence_transformer, k=k)\n",
    "print(f'NDCG@10: {score[0]}')\n",
    "print(f\"Precision@{k}: {score[1]}\")\n",
    "print(f\"Recall@{k}: {score[2]}\")\n",
    "print('\\n')\n",
    "k = 10\n",
    "score = evaluate_gte(qid2query_df, qrel_df, collection, sentence_transformer, k=k)\n",
    "print(f'NDCG@10: {score[0]}')\n",
    "print(f\"Precision@{k}: {score[1]}\")\n",
    "print(f\"Recall@{k}: {score[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380a73b-f33f-4ad5-8f02-80c1db75e11e",
   "metadata": {},
   "source": [
    "## Evaluate SYNGET Models\n",
    "This model is now finetuned on our synthetic positive pairs using one elu Layer followed by a linear Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de22e5-f33b-43a3-b669-72d31c202d20",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SYNGET-U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1a3cfcd-e51e-45af-b96a-5b6f4e8af30f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10: 0.1653624193548387\n",
      "Precision@5: 0.23978494623655916\n",
      "Recall@5: 0.029447296198577153\n",
      "\n",
      "\n",
      "NDCG@10: 0.1653624193548387\n",
      "Precision@10: 0.24301075268817207\n",
      "Recall@10: 0.05284969649480427\n"
     ]
    }
   ],
   "source": [
    "model = TwoTowerModel(candidates)\n",
    "model.load_weights(SYNGET_U)\n",
    "k = 5\n",
    "score = evaluate_two_tower(qid2query_df, qrel_df, model, collection, sentence_transformer, k=k)\n",
    "print(f'NDCG@10: {score[0]}')\n",
    "print(f\"Precision@{k}: {score[1]}\")\n",
    "print(f\"Recall@{k}: {score[2]}\")\n",
    "print('\\n')\n",
    "k = 10\n",
    "score = evaluate_two_tower(qid2query_df, qrel_df, model, collection, sentence_transformer, k=k)\n",
    "print(f'NDCG@10: {score[0]}')\n",
    "print(f\"Precision@{k}: {score[1]}\")\n",
    "print(f\"Recall@{k}: {score[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0090d5ef-d9b2-4f82-be5c-e2b45738cfba",
   "metadata": {},
   "source": [
    "### SYNGET-0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18cdc1cf-c519-4197-83dd-699a3afcf900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._current_learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "NDCG@10: 0.16914865591397849\n",
      "Precision@5: 0.26344086021505375\n",
      "Recall@5: 0.030466103954099443\n",
      "\n",
      "\n",
      "NDCG@10: 0.16914865591397849\n",
      "Precision@10: 0.25967741935483873\n",
      "Recall@10: 0.05712073493564846\n"
     ]
    }
   ],
   "source": [
    "model = TwoTowerModel(candidates)\n",
    "model.load_weights(SYNGET_06)\n",
    "k = 5\n",
    "score = evaluate_two_tower(qid2query_df, qrel_df, model, collection, sentence_transformer, k=k)\n",
    "print(f'NDCG@10: {score[0]}')\n",
    "print(f\"Precision@{k}: {score[1]}\")\n",
    "print(f\"Recall@{k}: {score[2]}\")\n",
    "print('\\n')\n",
    "k = 10\n",
    "score = evaluate_two_tower(qid2query_df, qrel_df, model, collection, sentence_transformer, k=k)\n",
    "print(f'NDCG@10: {score[0]}')\n",
    "print(f\"Precision@{k}: {score[1]}\")\n",
    "print(f\"Recall@{k}: {score[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62f038-e1f7-4179-8694-5c134f1d2f94",
   "metadata": {},
   "source": [
    "### SYNGET-0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f947395-6f26-427d-a2d1-25919da06c01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._current_learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "NDCG@10: 0.21971370967741932\n",
      "Precision@5: 0.32903225806451614\n",
      "Recall@5: 0.039629984038986085\n",
      "\n",
      "\n",
      "NDCG@10: 0.21971370967741932\n",
      "Precision@10: 0.31451612903225806\n",
      "Recall@10: 0.07222742633021043\n"
     ]
    }
   ],
   "source": [
    "model = TwoTowerModel(candidates)\n",
    "model.load_weights(SYNGET_07)\n",
    "k = 5\n",
    "score = evaluate_two_tower(qid2query_df, qrel_df, model, collection, sentence_transformer, k=k)\n",
    "print(f'NDCG@10: {score[0]}')\n",
    "print(f\"Precision@{k}: {score[1]}\")\n",
    "print(f\"Recall@{k}: {score[2]}\")\n",
    "print('\\n')\n",
    "k = 10\n",
    "score = evaluate_two_tower(qid2query_df, qrel_df, model, collection, sentence_transformer, k=k)\n",
    "print(f'NDCG@10: {score[0]}')\n",
    "print(f\"Precision@{k}: {score[1]}\")\n",
    "print(f\"Recall@{k}: {score[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453b2e9-ff54-4dc0-9c86-cca1d22f9fbe",
   "metadata": {},
   "source": [
    "### SYNGET-0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9355b74-c15e-49c0-853d-7024d8d906f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "NDCG@10: 0.6597959677419355\n",
      "Precision@5: 0.710752688172043\n",
      "Recall@5: 0.1700878859727594\n",
      "\n",
      "\n",
      "NDCG@10: 0.6597959677419355\n",
      "Precision@10: 0.6349462365591397\n",
      "Recall@10: 0.2531176025286843\n"
     ]
    }
   ],
   "source": [
    "model = TwoTowerModel(candidates)\n",
    "model.load_weights(SYNGET_08)\n",
    "k = 5\n",
    "score = evaluate_two_tower(qid2query_df, qrel_df, model, collection, sentence_transformer, k=k)\n",
    "print(f'NDCG@10: {score[0]}')\n",
    "print(f\"Precision@{k}: {score[1]}\")\n",
    "print(f\"Recall@{k}: {score[2]}\")\n",
    "print('\\n')\n",
    "k = 10\n",
    "score = evaluate_two_tower(qid2query_df, qrel_df, model, collection, sentence_transformer, k=k)\n",
    "print(f'NDCG@10: {score[0]}')\n",
    "print(f\"Precision@{k}: {score[1]}\")\n",
    "print(f\"Recall@{k}: {score[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa62e5-f8c6-4705-8f15-6df125f2f410",
   "metadata": {},
   "source": [
    "## SYNGET-0.8 AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8c4fe85-d227-4315-a121-a43e916989a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "NDCG@10: 0.5642075806451613\n",
      "Precision@5: 0.6258064516129033\n",
      "Recall@5: 0.12341903977208206\n",
      "\n",
      "\n",
      "NDCG@10: 0.5642075806451613\n",
      "Precision@10: 0.5725806451612904\n",
      "Recall@10: 0.20759569236918432\n"
     ]
    }
   ],
   "source": [
    "model = TwoTowerModel(candidates)\n",
    "model.load_weights(SYNGET_08_AC)\n",
    "k = 5\n",
    "score = evaluate_two_tower(qid2query_df, qrel_df, model, collection, sentence_transformer, k=k)\n",
    "print(f'NDCG@10: {score[0]}')\n",
    "print(f\"Precision@{k}: {score[1]}\")\n",
    "print(f\"Recall@{k}: {score[2]}\")\n",
    "print('\\n')\n",
    "k = 10\n",
    "score = evaluate_two_tower(qid2query_df, qrel_df, model, collection, sentence_transformer, k=k)\n",
    "print(f'NDCG@10: {score[0]}')\n",
    "print(f\"Precision@{k}: {score[1]}\")\n",
    "print(f\"Recall@{k}: {score[2]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
